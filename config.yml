# 全局配置
# 对于希望在同一时间使用多个配置文件的情况，例如两个GPU同时跑两个训练集：通过环境变量指定配置文件，不指定则默认为./config.yml

# 拟提供通用路径配置，统一存放数据，避免数据放得很乱
# 每个数据集与其对应的模型存放至统一路径下，后续所有的路径配置均为相对于datasetPath的路径
# 不填或者填空则路径为相对于项目根目录的路径
dataset_path: "Data/"

# preprocess_text 数据集预处理相关配置
# 注意， “:” 后需要加空格
preprocess_text:
  # 原始文本文件路径，文本格式应为{wav_path}|{speaker_name}|{text}。
  transcription_path: "all.list"
  # 数据清洗后文本路径，可以不填。不填则将在原始文本目录生成
  cleaned_path: ""
  # 训练集路径
  train_path: "train.list"
  # 验证集路径
  val_path: "val.list"
  # 配置文件路径
  config_path: "config.json"
  # 每个语言的验证集条数
  val_per_lang: 4
  # 验证集最大条数，多于的会被截断并放到训练集中
  max_val_total: 12
  # 是否进行数据清洗
  clean: true


# bert_gen 相关配置
# 注意， “:” 后需要加空格
bert_gen:
  # 训练数据集配置文件路径
  config_path: "config.json"
  # 并行数
  num_processes: 4
  # 使用设备：可选项 "cuda" 显卡推理，"cpu" cpu推理
  # 该选项同时决定了get_bert_feature的默认设备
  device: "cuda"
  # 使用多卡推理
  use_multi_device: false

# train 训练配置
# 注意， “:” 后需要加空格
train_ms:
  env:
    MASTER_ADDR: "localhost"
    MASTER_PORT: 10086
    WORLD_SIZE: 1
    LOCAL_RANK: 0
    RANK: 0
    # 可以填写任意名的环境变量
    # THE_ENV_VAR_YOU_NEED_TO_USE: "1234567"
  model: "models"
  # 配置文件路径
  config_path: "config.json"
  # 训练使用的worker，不建议超过CPU核心数
  num_workers: 16
  # 关闭此项可以节约接近50%的磁盘空间，但是可能导致实际训练速度变慢和更高的CPU使用率。
  spec_cache: True
  # 保存的检查点数量，多于此数目的权重会被删除来节省空间。
  keep_ckpts: 8


# webui webui配置
# 注意， “:” 后需要加空格
webui:
  # 推理设备
  device: "cuda"
  # 模型路径
  model: "models/G_0.pth"
  # 配置文件路径
  config_path: "config.json"
  # 端口号
  port: 6006
  # 是否公开部署，对外网开放
  share: false
  # 是否开启debug模式
  debug: false
